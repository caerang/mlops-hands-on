version: '3'
services:
  prediction_api:
    build: .
    container_name: "inference_container"
    ports:
      - "8009:8009"
